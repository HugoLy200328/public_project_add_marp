{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_curve\n",
    "from scipy.fftpack import dct\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../SavedFeatures/X_mfcc.npy')\n",
    "y = np.load('../SavedFeatures/y_mfcc.npy')\n",
    "X_dl = np.expand_dims(X, axis=-1)  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # to 2D\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)  # to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_val_predictions = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RF - MFCC===================\n",
      "Accuracy: 0.89730\n",
      "F1-Score  0.88827\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1904\n",
      "           1       0.98      0.90      0.94      1280\n",
      "\n",
      "    accuracy                           0.95      3184\n",
      "   macro avg       0.96      0.94      0.95      3184\n",
      "weighted avg       0.95      0.95      0.95      3184\n",
      "\n",
      "EER of Bonafine: ---------\n",
      "Equal Error Rate (EER): 0.05725\n",
      "EER Threshold: 0.32667\n",
      "EER of Spoof: ---------\n",
      "Equal Error Rate (EER): 0.94275\n",
      "EER Threshold: 0.68000\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, rf_val_predictions)\n",
    "f1_class_0 = f1_score(y_val, rf_val_predictions, pos_label=0)\n",
    "f1_class_1 = f1_score(y_val, rf_val_predictions, pos_label=1) \n",
    "f1_score = (f1_class_0 + f1_class_1)/2\n",
    "\n",
    "# TÃ­nh EER\n",
    "\n",
    "y_val_probabilities1 = rf_model.predict_proba(X_val)[:, 1]\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_val, y_val_probabilities1)\n",
    "frr1 = 1 - tpr1\n",
    "eer_index1 = np.nanargmin(np.abs(fpr1 - frr1))\n",
    "eer1 = fpr1[eer_index1] \n",
    "eer_threshold1 = thresholds1[eer_index1]\n",
    "\n",
    "\n",
    "y_val_probabilities = rf_model.predict_proba(X_val)[:, 0]\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_probabilities)\n",
    "frr = 1 - tpr\n",
    "eer_index = np.nanargmin(np.abs(fpr - frr))\n",
    "eer = fpr[eer_index]  \n",
    "eer_threshold = thresholds[eer_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"===================RF - MFCC===================\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"F1-Score  {f1_score:.5f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, rf_val_predictions))\n",
    "print(\"EER of Bonafine: ---------\")\n",
    "print(f\"Equal Error Rate (EER): {eer1:.5f}\")\n",
    "print(f\"EER Threshold: {eer_threshold1:.5f}\")\n",
    "print(\"EER of Spoof: ---------\")\n",
    "print(f\"Equal Error Rate (EER): {eer:.5f}\")\n",
    "print(f\"EER Threshold: {eer_threshold:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SavedModels/MFCC_rf_dfd.pkl\", 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rf_model, rf_val_predictions, X_train, X_val, y_train, y_val\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
