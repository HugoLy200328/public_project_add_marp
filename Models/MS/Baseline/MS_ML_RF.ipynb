{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_curve\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load features\n",
    "X = np.load('../SavedFeatures/X_mel_spec.npy',  allow_pickle=True)\n",
    "y = np.load('../SavedFeatures/y_mel_spec.npy',  allow_pickle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Đổi trường dữ liệu \n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # to 2D\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)  # to 2D\n",
    "\n",
    "del X, y  \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================RF - MS===================\n",
      "Accuracy: 0.91489\n",
      "F1-Score  0.90821\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1904\n",
      "           1       0.98      0.80      0.88      1280\n",
      "\n",
      "    accuracy                           0.91      3184\n",
      "   macro avg       0.93      0.90      0.91      3184\n",
      "weighted avg       0.92      0.91      0.91      3184\n",
      "\n",
      "EER of Bonafine: ---------\n",
      "Equal Error Rate (EER): 0.06775\n",
      "EER Threshold: 0.31333\n",
      "EER of Spoof: ---------\n",
      "Equal Error Rate (EER): 0.93225\n",
      "EER Threshold: 0.69333\n"
     ]
    }
   ],
   "source": [
    "rf_val_predictions = rf_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, rf_val_predictions)\n",
    "f1_class_0 = f1_score(y_val, rf_val_predictions, pos_label=0)\n",
    "f1_class_1 = f1_score(y_val, rf_val_predictions, pos_label=1) \n",
    "f1_score = (f1_class_0 + f1_class_1)/2\n",
    "\n",
    "# Tính EER\n",
    "\n",
    "\n",
    "y_val_probabilities1 = rf_model.predict_proba(X_val)[:, 1]\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_val, y_val_probabilities1)\n",
    "frr1 = 1 - tpr1\n",
    "eer_index1 = np.nanargmin(np.abs(fpr1 - frr1))\n",
    "eer1 = fpr1[eer_index1] \n",
    "eer_threshold1 = thresholds1[eer_index1]\n",
    "\n",
    "\n",
    "y_val_probabilities = rf_model.predict_proba(X_val)[:, 0]\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_probabilities)\n",
    "frr = 1 - tpr\n",
    "eer_index = np.nanargmin(np.abs(fpr - frr))\n",
    "eer = fpr[eer_index]  \n",
    "eer_threshold = thresholds[eer_index]\n",
    "\n",
    "\n",
    "\n",
    "print(\"===================RF - MS===================\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"F1-Score  {f1_score:.5f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, rf_val_predictions))\n",
    "print(\"EER of Bonafine: ---------\")\n",
    "print(f\"Equal Error Rate (EER): {eer1:.5f}\")\n",
    "print(f\"EER Threshold: {eer_threshold1:.5f}\")\n",
    "print(\"EER of Spoof: ---------\")\n",
    "print(f\"Equal Error Rate (EER): {eer:.5f}\")\n",
    "print(f\"EER Threshold: {eer_threshold:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as Pickle file\n",
    "with open(\"../SavedModel/MS_rf_dfd.pkl\", 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rf_model, X_train, X_val, y_train, y_val\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
