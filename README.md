ğŸ§ DeepFake Audio Detection using Acoustic Features
A machine learning and deep learning based approach to detect deepfake audio using acoustic features like MFCC, Mel-Spectrogram, CQCC, and F0.

ğŸ“Œ Overview
This project focuses on detecting deepfake (AI-generated) audio using various acoustic features and deep learning models. We extract features such as MFCC, Mel-Spectrogram, CQCC, and F0, then apply CNN-based architectures (like VGG16, ResNet50, and MobileNet) and ensemble methods with Stacking Classifier to classify genuine vs fake audio.

ğŸ§ª Features Used
MFCC (Mel Frequency Cepstral Coefficients)

Mel-Spectrogram

CQCC (Constant Q Cepstral Coefficients)

F0 (Fundamental Frequency)

ğŸ§  Models Applied
CNN Architectures: VGG16, ResNet50, MobileNet

Ensemble Learning: Stacking Classifier with Decision Tree as the meta-model

Optimization: Genetic Algorithm (GA) for model selection and hyperparameter tuning

ğŸ—ï¸ Architecture
Preprocessing: Convert audio files into acoustic features

Feature-Specific Modeling: Train a dedicated CNN for each feature type

Ensemble: Combine predictions using Stacking Classifier

Optimization: Use Genetic Algorithm to optimize model combination

ğŸ“ Project Structure
bash
Sao chÃ©p
Chá»‰nh sá»­a
deepfake-audio-detection/
â”œâ”€â”€ data/                  # Audio data
â”œâ”€â”€ features/              # Extracted features
â”œâ”€â”€ models/                # Saved models
â”œâ”€â”€ notebooks/             # Jupyter notebooks for EDA and experiments
â”œâ”€â”€ utils/                 # Feature extraction and training scripts
â”œâ”€â”€ main.py                # Main pipeline
â”œâ”€â”€ requirements.txt       
â””â”€â”€ README.md
ğŸš€ Getting Started
Clone the repo
bash
Sao chÃ©p
Chá»‰nh sá»­a
git clone https://github.com/your-username/deepfake-audio-detection.git
cd deepfake-audio-detection
Install dependencies
bash
Sao chÃ©p
Chá»‰nh sá»­a
pip install -r requirements.txt
Run the pipeline
bash
Sao chÃ©p
Chá»‰nh sá»­a
python main.py
ğŸ§¬ Genetic Algorithm Optimization
We use GA to:

Select the best CNN model for each feature

Optimize stacking weights and meta-model hyperparameters

ğŸ“Š Results
Feature	Best Model	Accuracy
MFCC	VGG16	92.5%
Mel-Spectrogram	ResNet50	94.1%
CQCC	MobileNet	91.3%
F0	VGG16	89.8%

Stacking Ensemble achieves an overall accuracy of 96.4%.

ğŸ“š References
WaveFake: Detecting Fake Speech using Audio Fingerprints

DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake Voices

ğŸ“„ License
This project is licensed under the MIT License.
